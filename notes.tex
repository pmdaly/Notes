\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{blindtext}
\usepackage{listings}
\usepackage{color}
\usepackage{xcolor}

% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{10} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{10}  % for normal
\DeclareFixedFont{\ttbcol}{T1}{txtt}{bx}{n}{8} % for bold
\DeclareFixedFont{\ttmcol}{T1}{txtt}{m}{n}{8}  % for normal

% Custom colors
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}


% Python style for highlighting
\newcommand\pythonstyle{\lstset{
    basicstyle=\ttm,
    commentstyle=\color{gray!70},
    emph={MyClass,__init__},          % Custom highlighting
    emphstyle=\ttb\color{deepred},    % Custom highlighting style
    keywordstyle=\ttb\color{deepblue},
    %frame=tb,                         % Any extra options here
    language=Python,
    numbers=left,
    numbersep=10pt,
    otherkeywords={self},             % Add keywords here
    showstringspaces=false            %
    stringstyle=\color{deepgreen},
    breaklines
}}
\newcommand\pythonstylecol{\lstset{
    basicstyle=\ttmcol,
    commentstyle=\color{gray!70},
    emph={MyClass,__init__},          % Custom highlighting
    emphstyle=\ttbcol\color{deepred},    % Custom highlighting style
    keywordstyle=\ttbcol\color{deepblue},
    %frame=tb,                         % Any extra options here
    language=Python,
    numbers=left,
    numbersep=10pt,
    otherkeywords={self},             % Add keywords here
    showstringspaces=false            %
    stringstyle=\color{deepgreen},
    breaklines
}}


% Python environment
\lstnewenvironment{python}[1][]{
  \pythonstyle
  \lstset{#1}
}{}
\lstnewenvironment{pythoncol}[1][]{
  \pythonstylecol
  \lstset{#1}
}{}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}

\usepackage{hyperref}

\begin{document}
\begin{center}
  \vspace*{10mm}
  {\bfseries {\huge General Notes}}\\
  \vspace*{5mm}
  {\bfseries {CS, ML and Stats}
    \\ \vspace*{2mm} {\large Patrick Daly}
  }
\end{center}

\newpage

\tableofcontents
\newpage

\section{Computer Science}

\subsection{Algorithms}

\paragraph{DFS}  Time: O(n), Space: O(n)

Solution exists far away.\\

Recursive
\begin{python}
def dfs(node):
  if node:
    # do stuff if pre-order
    if node.left:
      dfs(node.left)
    # do stuff if in-order
    if node.right:
      dfs(node.right)
    # do stuff if post-order
\end{python}

Iterative
\begin{python}
def dfs(node): # if bst, may need to swap search left/right
    visited = set()
    stack = [node]
    while stack:
        current = stack.pop(-1)
        print(current.val)
        if current not in visited:
            visited.add(current)
        if current.left and current.left not in visited:
            stack.append(current.left)
        if current.right and current.right not in visited:
            stack.append(current.right)
    return visited
\end{python}

\paragraph{BFS} Time: O(n), Space(n)

Solution exists nearby.\\

Iterative \\
\begin{python}
def bfs(node):
    stack = [node]
    while stack:
        current = stack.pop(-1)
        if current.left:
            stack.append(current.left)
        if current.right:
            stack.append(current.right)
\end{python}

\paragraph{Mergesort} Time: O(nlogn), Space: O(n)

\begin{python}
def mergesort(array, start, end):
    if start < end:
        mid = (start+end) // 2
        mergesort(array, start, mid)
        mergesort(array, mid+1, end)
        merge(array, start, mid, end)
\end{python}

\begin{python}
def merge(array, start, mid, end):
    left = array[start: mid+1]
    right = array[mid+1: end+1]
    i, j, k = 0, 0, start
    while i < len(left) and j < len(right):
        if left[i] < right[j]:
            array[k] = left[i]
            i += 1
        else:
            array[k] = right[j]
            j += 1
        k += 1
    if j == len(right):
        array[k: end+1] = left[i:]
\end{python}

\paragraph{Binary Search}

\begin{python}
def binarysearch(array, val, low, high):
    if high < low:
        # can also return high or low index
        return 'Not found!'
    mid = (low + high) // 2
    if array[mid] > val:
        return binarysearch(array, val, low, mid-1)
    elif array[mid] < val:
        return binarysearch(array, val, mid+1, high)
    return mid
\end{python}


\paragraph{Greatest Common Divisor (GCD)} Time: ?, Space: ?

Euclid: Time: O($ln^2$min(a, b)), Space: O(1)
\begin{python}
def gcd(a, b):
    return gcd(b, a % b) if b else a
\end{python}

Stein: Time: 60\% faster than Euclid in theory, similar in practice Space: O(1)
\begin{python}
def stein(a, b):
    # binary gcd
    if a == b: return a
    if a == 0: return v
    if b == 0: return a
    if ~a & 1: # a is even
        if b & 1: # b is odd
            return stein(a >> 1, v)
        else: # b is even
            return stein(a >> 1, b >> 1) << 1
    else:
        if ~b & 1: # b is even
            return stein(a, b >> 1)
        else: # b is odd
            if a > b:
                return stein((a-b) >> 1, b)
            else:
                return stein(u, (b-a) >> 1)
\end{python}


\paragraph{Fibonacci} Time: O(n), Space: O(1)

Iterative
\begin{python}
def fib_iterative(n):
    if n == 0: return 0
    if n == 1: return 1
    first, seecond, fibn = 0, 1, 0
    for i in range(2, n+1):
      fib_n = fib_n2 + fib_n1
      fib_n = fib_n2
      fib_n2 = fib_n
    return fibn
\end{python}

Recursive
\begin{python}
def fib_recursive(n, dp={0: 0, 1: 1}):
    if n in dp:
        return dp[n]
    return fib_recursive(n-2, dp) + fib_recursive(n-1, dp)
\end{python}


\paragraph{Longest Increasing Subsequence} Time: O(nlogn), Space: O(n)

\begin{python}
def lis(nums):
    tails = [0]*len(nums)
    maxlen = 0
    for num in nums:
        start, end = 0, maxlen
        while start != end:
            mid = (start+end)//2
            if tails[mid] < num:
                start = mid + 1
            else:
                end = mid
        tails[start] = num
        maxlen = max(maxlen, start+1)
    return maxlen
\end{python}


\paragraph{Topological Sort} Time: (V + E), Space: O(V)

  Identifying a linear ordering of vertices such that if the graph G contains
  an edge (u, v), then u appears before v in the ordering.  Often used in
  identifying depency graphs or sources in a event chain.  Multiple solutions
  may exist.

\begin{python}
def topo_sort(G):
    def dfs(u):
        visited.add(u)
        for v in G[u]:
            if v not in visited:
              dfs(v)
        order.insert(u)
    order = list()
    visited = set()
    for u in G:
        if u not in visited:
          dfs(u)
    return order
\end{python}


\subsection{Data Sctructures}

\subsection{Linux}

\paragraph{Common Commands}
\begin{enumerate}
  \item grep
  \item awk
  \item xargs
  \item find
  \item cut
\end{enumerate}

\paragraph{Software \& Packages}
\begin{enumerate}
  \item Vim
  \item Tmux
  \item Ranger
  \item Autojump
  \item Tldr
  \item Jq
  \item Ccat
\end{enumerate}

\section{Machine Learning}
\subsection{Supervised}
\subsubsection{Ordinary Least Squares (OLS)}
\subsubsection{Generalized Linear Model(GLM)}
\subsubsection{Logistic Regression}
\subsubsection{Linear Discriminant Analysis}
\subsubsection{Support Vector Machines}
\subsubsection{K-Nearest Neighbors}
\subsubsection{Gaussian Process}
\subsubsection{K-Nearest Neighbors}
\subsubsection{Decision Trees}
\subsubsection{Random Forest}
\subsubsection{Gaussian Process}
\subsubsection{Naive Bayes}
\subsubsection{Kalman Filter? dunno where this should go yet... maybe estimation section?}
\subsection{Unsupervised}
\subsubsection{Gaussan Mixture Models}
\subsubsection{K-Means}
\subsubsection{Density-Based Spatial Clustering of Applications with Noise (DBSCAN)}
\subsubsection{Spectral Clustering}
\subsubsection{Hierarchical Clustering}
\subsubsection{Factor Analysis}
\subsubsection{Independent Component Analysis}
\subsubsection{Principal Component Analysis}
\subsubsection{Non-Negative Matrix Factorization (NMF)}
\subsubsection{Latent Dirichlet Allocation (LDA)}
\subsubsection{Outliear Detection?}

\section{Deep Learning}
\subsection{Convolutional Networks}
\subsection{Recurrent Networks}
\subsection{Long Short-Term Memory (LSTM)}
\subsection{Autoencoders}
\subsection{Reinforcement Learning}

\section{Linear Algebra}
\subsection{Norms}
\subsubsection{Euclidean / Frobenius}
\subsubsection{Manhatten}
\subsubsection{Infinity}
\subsubsection{Nuclear}
\subsubsection{Spectral}
\subsubsection{Symmetric}
\subsubsection{Positive Definite}
\subsubsection{Positive Semi-Definite}
\subsubsection{Negative Definite}
\subsubsection{Negative Semi-Definite}
\subsection{Eigendecomposition}
\subsection{Singular Value Decomposition (SVD)}
\subsection{Principal Component Analysis (PCA)}
\subsection{Independent Component Analysis (ICA)}
\subsection{Canonical Component Analysis (CCA)}
\subsection{Factor Analysis}

\section{Statistics}
\subsection{Probability Theory}
\subsection{Distributions}
\subsection{Combinatorics}



\iffalse
\begin{enumerate}
    \begin{item}
      Machine Learning (combine with stats?)
      \begin{enumerate}
          \begin{item}
            Supervised
            \begin{enumerate}
                \begin{item}

                  Generalized Linear Model (GLM)

                  \begin{enumerate}

                      Links

                      \begin{item}
                        Normal
                      \end{item}

                      \begin{item}
                        Exponential
                      \end{item}

                      \begin{item}
                        Poisson
                      \end{item}

                      \begin{item}
                        Bernoulli
                      \end{item}

                      \begin{item}
                        Binomial
                      \end{item}

                      \begin{item}
                        Categorical
                      \end{item}

                      \begin{item}
                        Multinomail
                      \end{item}
                  \end{enumerate}
            \end{enumerate}
          \end{item}
      \end{enumerate}
    \end{item}
    \end{item}

    \begin{item}
      Statistics

      \begin{enumerate}

          \begin{item}
            Probability Theory
          \end{item}

          \begin{item}

            Distributions

            \begin{enumerate}

                \begin{item}

                  Discrete

                  \begin{enumerate}

                      \begin{item}
                        Binomial
                      \end{item}

                      \begin{item}
                        Geometric
                      \end{item}

                      \begin{item}
                        Uniform
                      \end{item}

                      \begin{item}
                        Exponential
                      \end{item}

                      \begin{item}
                        Poisson
                      \end{item}

                  \end{enumerate}

                \end{item}

                \begin{item}

                  Continuous

                  \begin{enumerate}

                      \begin{item}
                        Normal
                      \end{item}

                      \begin{item}
                        Log-Normal
                      \end{item}

                      \begin{item}
                        Laplace
                      \end{item}

                      \begin{item}
                        Gamma
                      \end{item}

                  \end{enumerate}

                \end{item}

            \end{enumerate}

          \end{item}

          \begin{item}
            Combinatorics
          \end{item}

      \end{enumerate}

    \end{item}

\end{enumerate}
\fi

\end{document}
